# WEB DATA SCRAPING (DEMO VERSION)

This is a flexible and easy to use **web scraping tool** built in Python.
This repo is just the **demo** of my scraping tool, created with the purpose of learning, testing and showing the capabilities of the tool.
With just one command, scrape structured data and export it to the format you prefer.

![Demo Screenshot](examples/screenshot.png) 

---

## âœ¨ Features (Demo Version)

- ğŸ“¥ **CSV Input** â†’ Provide a list of URLs to scrape.
- âš™ï¸ **Configurable fields** via `config.json` (set which elements to extract).
- ğŸ§­ **Smart scraping** with Selenium + BeautifulSoup.
- ğŸ¯ **Output Options**: CSV / Excel.
- ğŸ”„ **Retries** â†’ Automatically retries failed pages a customizable number of times.
- ğŸ“‘ **Skipped URLs log** â†’ URLs that couldnâ€™t be scraped are saved to `skipped_report.csv`.
- ğŸ•¶ **Headless Mode** â†’ Run without opening the browser.
- ğŸ² **Random User-Agent Rotation** â†’ Helps reduce detection.

---

## ğŸš€ Full Version Includes

- âœ… Wider range of supported input/output formats

- âœ… Advanced and customizable CLI and config.json settings

- âœ… New logger handler which redirects its output to a .log file

- âœ… Advanced anti-bot detection bypass

- âœ… Login automation

- âœ… Captcha handling (manual or automatic)

- âœ… Google sheets integration

- âœ… Database export (SQLite/Postgres)

- âœ… API export (send JSON via post)

- âœ… Scheduler / cron automation

- âœ… Dockerfile

- âœ… Proxy rotation
  

<br><br>ğŸ“© Contact me for the full tool or custom scrapers (Amazon, LinkedIn, competitor monitoring, lead generation).<br><br>
**NOTE: CUSTOM FEATURES CAN BE ADDED TO THE FINAL PRODUCT IN ORDER TO MEET THE CLIENTS NEEDS. THESE ARE JUST A LIST OF FEATURES ALREADY INCLUDED IN THE PREMIUM VERSION OF THE PRODUCT**

---

## ğŸ“¦ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/yourusername/web-data-scraper-demo.git
cd web-data-scraper-demo
pip install -r requirements.txt
```

Alternatively, run the 'run.sh' script

```bash
bash run.sh
```

---

## ğŸ–¥ Usage

```bash
python3 scraper.py input.csv --output excel --limit 5
```
**Arguments**

- input (required): Input file with URLs (CSV or Excel). Must contain a url column.
- --output (optional): Output format (csv or excel). Default = CSV.
- --limit: Scrape only first N URLs.

---

## âš™ï¸ Configuration

Edit config.json to define what to scrape:

```json
{
  "fields": {
    "title": "title",
    "price": ".price_color",
    "availability": ".instock.availability"
  },
  "headless": true,
  "proxy": null,
  "user_agents": [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
  ]
}
```

---

## ğŸ“¢ Hire Me

ğŸ’¡ This demo shows the foundation.
I build custom web scrapers for:

- Small businesses

- Marketers

- Amazon/E-commerce sellers

- Lead generation agencies

<br>-- BASIC SCRAPER (NO EXTRAS): 50â‚¬<br>
-- PROFESSIONAL LEVEL SCRAPER: 100â‚¬ (WITH THE LISTED EXTRAS)<br>
-- PREMIUM EDITION SCRAPER: 100â‚¬-500â‚¬ (LISTED EXTRAS + CUSTOM CLIENT REQUESTED FEATURES)<br>

ğŸ‘‰ Reach me on:<br>
  | [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/juanmanuelreyrojas)
  | [![Upwork](https://img.shields.io/badge/Upwork-6fda44?style=for-the-badge&logo=upwork&logoColor=white)](https://www.upwork.com/freelancers/~0139afec838e1b0e09)
  | [![Fiverr](https://img.shields.io/badge/Fiverr-1DBF73?style=for-the-badge&logo=fiverr&logoColor=white)](https://es.fiverr.com/s/GzWLpwL) 
  | [![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:jumareyrojas1@gmail.com)
  |

---

## ğŸ“œ License

This demo is provided for educational and portfolio purposes, it is not intended for scraping sites against their Terms of Service.
  
  






